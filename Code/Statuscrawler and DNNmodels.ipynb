{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataFestSourceCode.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SfLrQKS_Npbb",
        "B_qfzXUwYAby"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFYPWQNAjWYe",
        "colab_type": "text"
      },
      "source": [
        "# Part1. Prepare datasets\n",
        "*   Merge data from Yelp with Google places database\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY3khhHmIOo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktzsItgTGuoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import calendar\n",
        "from datetime import timedelta\n",
        "import copy\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from google.colab import files\n",
        "import urllib.parse\n",
        "import csv\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4xYmL-hGfbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_rest_name = \"Popeye's SupplÃ©ments MontrÃ©al\"\n",
        "# clean_rest_name = re.sub(r'[^a-zA-Z0-9_\\s&\\']+', '', raw_rest_name2)\n",
        "url_rest_name = urllib.parse.quote(clean_rest_name)\n",
        "url_rest_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfLrQKS_Npbb",
        "colab_type": "text"
      },
      "source": [
        "## Load data from csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jVtsHCTNaRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "######################### Data loader ###########################################\n",
        "################################################################################\n",
        "#Data loader\n",
        "raw_data_array = list(csv.reader(open(\"/content/drive/My Drive/DataFest/merged_rest_info_new.csv\")))\n",
        "raw_data_array.pop(0)\n",
        "raw_data = pd.read_csv(\"/content/drive/My Drive/DataFest/merged_rest_info_new.csv\",encoding = \"ISO-8859-1\")\n",
        "clean_data = copy.deepcopy(raw_data)\n",
        "lat_lst = list(raw_data.latitude)\n",
        "lng_lst = list(raw_data.longitude)\n",
        "rest_name_lst = list(raw_data.name)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21RUHs_xTkYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(rest_name_lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_qfzXUwYAby",
        "colab_type": "text"
      },
      "source": [
        "## Determine the closure of each restaurant using Google places API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymAGA0pkwXYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parameters\n",
        "num_closed_temp = 0\n",
        "# num_closed_perm = 0\n",
        "num_inv_coord = 0\n",
        "num_rest_processed = 0\n",
        "\n",
        "for idx in range(42002, len(rest_name_lst)):\n",
        "  num_rest_processed += 1\n",
        "  print(\"num_rest_processed:{}  \".format(num_rest_processed))\n",
        "\n",
        "  #Parsing the name of Restaurant\n",
        "  raw_rest_name = raw_data_array[idx][3]\n",
        "  clean_rest_name = re.sub(r'[^a-zA-Z0-9_\\s&\\']+', '', raw_rest_name)\n",
        "  url_rest_name = urllib.parse.quote(clean_rest_name)\n",
        "  print(\"\\traw_rest_name:{}  clean_rest_name:{} \".format(raw_rest_name, clean_rest_name))\n",
        "\n",
        "  #Parsing latitude and longitude\n",
        "  lat_y, lng_y = lat_lst[idx], lng_lst[idx]\n",
        "\n",
        "  #Fetch business status\n",
        "  url_prefix = \"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?\"\n",
        "  url_input = \"input=\" + url_rest_name\n",
        "  url_inputtype = \"&inputtype=textquery\"\n",
        "  url_fiels = \"&fields=business_status,formatted_address,name,rating,place_id,geometry\"\n",
        "  url_locationbias = \"&locationbias=point:\" + str(lat_y) + \",\" + str(lng_y)\n",
        "  url_key = \"&key=\" + api_key\n",
        "  url = url_prefix + url_input + url_inputtype + url_fiels + url_locationbias + url_key\n",
        "  respon = requests.get(url)\n",
        "  results = json.loads(respon.text)['candidates']\n",
        "\n",
        "  # If google api find resturant information\n",
        "  if len(results) != 0 and \"business_status\" in results[0]:\n",
        "    result = results[0]\n",
        "    status = result[\"business_status\"]\n",
        "    lat_g, lng_g = result['geometry']['location']['lat'], result['geometry']['location']['lng']\n",
        "    # Validate coordinates\n",
        "    if abs(lat_y - float(lat_g)) < 0.05 and abs(lng_y - float(lng_g)) < 0.05:\n",
        "      # Update clean data frame\n",
        "      clean_data.loc[idx,\"Found_by_g\"] = True\n",
        "      clean_data.loc[idx,\"status_g\"] = status\n",
        "      clean_data.loc[idx,\"name_g\"] = result['name']\n",
        "      clean_data.loc[idx,\"place_id_g\"] = result['place_id']\n",
        "      clean_data.loc[idx,\"lat_g\"] = lat_g\n",
        "      clean_data.loc[idx,\"lng_g\"] = lng_g\n",
        "      if \"rating\" in result:\n",
        "        clean_data.loc[idx,\"rating_g\"] = result['rating']\n",
        "      # clean_data.loc[idx,\"types_g\"] = result['types']\n",
        "      clean_data.loc[idx,\"formatted_address_g\"] = result['formatted_address']\n",
        "      \n",
        "      print(\"\\tstatus:{}   \".format(status))\n",
        "      if status == \"CLOSED_TEMPORARILY\":\n",
        "          num_closed_temp += 1\n",
        "          print(\"num_closed_temp:{}\".format(num_closed_temp))\n",
        "    else:\n",
        "      print(\"\\tNot found:Invalid coordinates\")\n",
        "      clean_data.loc[idx,\"More\"] = \"CoordError\"\n",
        "      clean_data.loc[idx,\"Found_by_g\"] = False\n",
        "      num_inv_coord += 1\n",
        "      print(\"num_inv_coord:{}\".format(num_inv_coord))\n",
        "  else:\n",
        "    print(\"\\tNot found:No resturant information\")\n",
        "    clean_data.loc[idx,\"More\"] = \"NoInfo\"\n",
        "    clean_data.loc[idx,\"Found_by_g\"] = False\n",
        "\n",
        "clean_data.to_csv('/content/drive/My Drive/DataFest/merged_rest_info_new.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX52KC-h4O63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_data.to_csv('/content/drive/My Drive/DataFest/upto_34901_merged_rest_info.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XASr6v3BYhKN",
        "colab_type": "text"
      },
      "source": [
        "## Merge datasets "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaK81ngij3kz",
        "colab_type": "text"
      },
      "source": [
        "# Part2. Preprocess data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv5FDJrCo-AE",
        "colab_type": "text"
      },
      "source": [
        "## Helper code\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxiduevBpKUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import normalize\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsl1qxfIx9IE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = pd.read_csv(\"/content/drive/My Drive/DataFest/merged_rest_info.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKQEBQZTyFfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SCOoqzbyRxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rest_info_sequence = raw_data.iloc[[0, 3], [3, 4]]\n",
        "rest_info = rest_info_sequence.to_numpy(dtype='float') ## Using int?\n",
        "rest_info\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaY3lL-85iuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normed_matrix = normalize(rest_info, axis=0, norm='l1')\n",
        "normed_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNbfmo6X5tE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy = np.array([[-1 , 0, 1], [-1,0,  1]])\n",
        "normed_matrix = normalize(dummy, axis=0, norm='l1')\n",
        "normed_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3i-vHIW6uss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.get_dummies([1 , 2 ,3]).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiPzoO2EpdB8",
        "colab_type": "text"
      },
      "source": [
        "## Random Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8jY1VajkDed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DatasetFromCSV(Dataset):\n",
        "    def __init__(self, csv_path, transform=None):\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        # self.labels = pd.get_dummies(self.data['labels']).to_numpy()\n",
        "        self.labels = self.data['labels']\n",
        "        # self.labels = self.labels.replace({1:0})\n",
        "        # self.labels = self.labels.replace({2:1})\n",
        "        self.count_row  = self.data.shape[0] \n",
        "        self.count_col  = self.data.shape[1]\n",
        "        # self.rests_info = self.data.iloc[:,[0,self.count_col]].to_numpy(dtype='float') ## Using int?  \n",
        "        self.rests_info = self.data.drop('labels', axis=1).to_numpy(dtype='float32')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # This method should return only 1 sample and label \n",
        "        # (according to \"index\"), not the whole dataset\n",
        "        rest_info = self.rests_info[index]\n",
        "        label = self.labels[index]\n",
        "        return rest_info, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xshmnzXoAA61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/DataFest/clean_binary_6340_7000.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGSQZ_LFYzRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leI4bD5E4CTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rests_info = data.drop('labels', axis=1).to_numpy(dtype='float32')\n",
        "rests_info.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yMTECk17pDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=50)\n",
        "pca.fit(rests_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxiw68xT7zyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca.singular_values_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWadBd3g1pDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "data_embedded = TSNE(n_components=2).fit_transform(rests_info)\n",
        "data_embedded.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc4hZQYk2tCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "palette = sns.color_palette(\"bright\", 2)\n",
        "sns.scatterplot(data_embedded[:,0], data_embedded[:,1], hue=data['labels'], legend='full', palette=palette)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k94WJ27ZWdqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = data['labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AzOCNIrAGZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = pd.get_dummies(data['labels']).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0MXv6-AALCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.shape(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PelQJXDxLipC",
        "colab_type": "code",
        "outputId": "9ba2f12c-4527-4b76-97ef-25a626665ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "labels.value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    3659\n",
              "0    3382\n",
              "1    2958\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqEUWqUPAban",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rests_info = data.drop('labels', axis=1).to_numpy(dtype='float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvX15C8SA8VK",
        "colab_type": "code",
        "outputId": "45efd362-cccb-4111-9216-2823eb202745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(rests_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10340, 108)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5FFHYxo_C_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset = DatasetFromCSV(\"/content/drive/My Drive/DataFest/clean_binary_6340_7000.csv\")\n",
        "dataset = DatasetFromCSV(\"/content/drive/My Drive/DataFest/6.12/clean_multi_6340_7000.csv\")\n",
        "batch_size = 100\n",
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 20\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ur-bCZUXdje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2j_7dH7bzo8",
        "colab_type": "code",
        "outputId": "a3bbdcf4-29cd-4605-e1b5-e2b3bae4edb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "dataset.labels.value_counts()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    7000\n",
              "0    3382\n",
              "1    2958\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em0MVVvoTIBW",
        "colab_type": "text"
      },
      "source": [
        "#Part3. Main Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC3QHFE0TNCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# inputs, n_hidden0, n_hidden1, out = 91, 64, 28, 3\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(inputs, n_hidden0, bias = True), \n",
        "#     nn.relu(), \n",
        "#     nn.Linear(n_hidden0, n_hidden1, bias = True),\n",
        "#     nn.relu(),\n",
        "#     nn.Linear(n_hidden1, out, bias = True),\n",
        "#     # nn.Softmax()\n",
        "# )\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD3Pi-mpifHT",
        "colab_type": "text"
      },
      "source": [
        "## Design model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA4zctLjKldi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, inputs, n_hidden0, n_hidden1, out):\n",
        "        super(Net, self).__init__()\n",
        "        self.n_hidden0 = n_hidden0\n",
        "        self.n_hidden1 = n_hidden1\n",
        "        self.fc1 = nn.Linear(inputs, n_hidden0)\n",
        "        self.fc2 = nn.Linear(n_hidden0, n_hidden1)\n",
        "        self.fc3 = nn.Linear(n_hidden1, out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of5nvpUXfUns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NetWithDropOut(nn.Module):\n",
        "    def __init__(self, inputs, n_hidden0, n_hidden1, out):\n",
        "        super(NetWithDropOut, self).__init__()\n",
        "        self.n_hidden0 = n_hidden0\n",
        "        self.n_hidden1 = n_hidden1\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.fc1 = nn.Linear(inputs, n_hidden0)\n",
        "        self.fc2 = nn.Linear(n_hidden0, n_hidden1)\n",
        "        self.fc3 = nn.Linear(n_hidden1, out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        # x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        # x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6nronxc1LSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=4, stride=1, padding=0)\n",
        "        self.pool = nn.MaxPool1d(3, 2)\n",
        "        self.conv2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2, stride=1, padding=0)\n",
        "        self.fc1 = nn.Linear(25, 10)\n",
        "        self.fc2 = nn.Linear(10, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "model = CNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csBIjk7E2T5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pool of size=3, stride=2\n",
        "m = nn.MaxPool1d(3, stride=2)\n",
        "input = torch.randn(1, 1, 109)\n",
        "# >>> output = m(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsGKXpmS3ECN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=4, stride=1, padding=0)\n",
        "output = conv1(input)\n",
        "pool = nn.MaxPool1d(3, 2)\n",
        "output = pool(output)\n",
        "conv2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2, stride=1, padding=0)\n",
        "output = pool(conv2(output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ44bsKE66hu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = torch.randn(30, 109)\n",
        "output = input.unsqueeze(1).unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_-Q15CI7CZC",
        "colab_type": "code",
        "outputId": "329d6a81-eb1a-455e-c7b5-59c6707ccff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1wvX96x2eaJ",
        "colab_type": "code",
        "outputId": "0061e8b0-4c5d-4a85-d00d-30e9a4047e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 54])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njv0nfNq3sLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNetBN(nn.Module):\n",
        "    def __init__(self): \n",
        "        super(MyNetBN, self).__init__()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(109, 48),\n",
        "            nn.BatchNorm1d(48), #applying batch norm\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 24),\n",
        "            nn.BatchNorm1d(24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, 2)\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = MyNetBN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCrOj_5E4U44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyNetBN(nn.Module):\n",
        "    def __init__(self,n_hidden0,n_hidden1): \n",
        "        super(MyNetBN, self).__init__()\n",
        "        self.n_hidden0 = n_hidden0\n",
        "        self.n_hidden1 = n_hidden1\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(109, 34),\n",
        "            nn.Dropout(0.2), #50 % probability \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(34, 20),\n",
        "            nn.Dropout(0.2), #50 % probability \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(20, 2),\n",
        "        )\n",
        "             \n",
        "    def forward(self, x):\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNgE2rGTe4c7",
        "colab_type": "text"
      },
      "source": [
        "##Construct loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkXoq2p1ioMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vmV3BgjiwGL",
        "colab_type": "text"
      },
      "source": [
        "##Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "131as915i1Lv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch,criterion,optimizer):\n",
        "# def train(epoch):\n",
        "  average_loss = 0\n",
        "  length = 0\n",
        "  for batch_idx, (inputs, target) in enumerate(train_loader):\n",
        "      length += 1\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #forward + backward + update  \n",
        "      # outputs = model(inputs).squeeze()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # print('epoch: ', epoch + 1, 'batch_idx: ', batch_idx + 1 ,' loss: ', loss.item())\n",
        "      # if (batch_idx % 100 == 0):\n",
        "      #   print('[%d, %5d] loss: %f' % (epoch + 1, batch_idx + 1, loss.item()))\n",
        "      average_loss += loss.item()\n",
        "  print('[%d] loss: %f' % (epoch + 1, average_loss/length))\n",
        "  return average_loss/length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv71Hoo3khit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # label_num = 2\n",
        "    label_num = 3\n",
        "    class_correct = list(0. for i in range(label_num))\n",
        "    class_total = list(0. for i in range(label_num))\n",
        "    class_accuracy = list(0. for i in range(label_num))\n",
        "    average_accuracy = 0\n",
        "    # all_label = [0,1]\n",
        "    all_label = [0, 1, 2]\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in validation_loader:\n",
        "            restaurants, labels = data\n",
        "            # outputs = model(restaurants).squeeze()\n",
        "            outputs = model(restaurants)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "    print('Total Accuracy of the network on the %d test restaurant: %d %%' % (total, 100 * correct / total))\n",
        "    for i in range(label_num):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            all_label[i], 100 * class_correct[i] / class_total[i]))\n",
        "        class_accuracy[i] = class_correct[i] / class_total[i]\n",
        "    average_accuracy = sum(class_accuracy)/label_num\n",
        "    print('Average Accuracy of the network on the %d test restaurant: %d %%' % (total, 100 * average_accuracy))\n",
        "    return 100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAkvg0sInJY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_with_class_output():    \n",
        "    class_correct = list(0. for i in range(3))\n",
        "    class_total = list(0. for i in range(3))\n",
        "    with torch.no_grad():\n",
        "        for data in validation_loader:\n",
        "            restaurants, labels = data\n",
        "            outputs = model(restaurants)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(3):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    for i in range(3):\n",
        "        print('Accuracy of %5s : %2d %%' % (\n",
        "            label[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxVN5nOrF5AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####--Selection--loop---###\n",
        "highest_accuracy = 0\n",
        "h0 = 0\n",
        "h1 = 0\n",
        "Epochs = []\n",
        "Loss = []\n",
        "valaccuracy = []\n",
        "for hidden_0 in [32, 48, 64, 128]:\n",
        "    for hidden_1 in [14, 20, 32, 48, 60]:\n",
        "        model = NetWithDropOut(109, hidden_0, hidden_1, 3)\n",
        "        # model = MyNetBN(hidden_0, hidden_1)\n",
        "        print('num_hidden 0 :%d; num_hidden 1: %d' % (model.n_hidden0, model.n_hidden1))\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.2)\n",
        "        for epoch in range(1500):\n",
        "            Epochs.append(epoch)\n",
        "            loss = train(epoch,criterion,optimizer)\n",
        "            Loss.append(loss)\n",
        "            accuracy = test()\n",
        "            valaccuracy.append(accuracy)\n",
        "            if highest_accuracy < accuracy: \n",
        "                highest_accuracy = accuracy\n",
        "                h1=hidden_1\n",
        "                h0=hidden_0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYDWMvwwqJg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "highest_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAWiwYaIRUqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valaccuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh7mCi1kshUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymYj4B1osi5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRqdXX_Qod7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_epochs = 10\n",
        "# for epoch in range(num_epochs):\n",
        "#     # Train:   \n",
        "#     for batch_index, (data, labels) in enumerate(train_loader):\n",
        "#         pred = model(data)\n",
        "#         loss = criterion(pred, labels)\n",
        "#         print('epoch: ', epoch + 1, 'batch_index: ', batch_index + 1 ,' loss: ', loss.item())\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZTm7J5FS89w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "valaccuracy = np.array(valaccuracy)\n",
        "Loss = np.array(Loss)\n",
        "Epochs = np.array(Epochs)\n",
        "\n",
        "with open('/content/drive/My Drive/DataFest/6.12/learning_curve_multi.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=',')\n",
        "    for row in range(0,Epochs.shape[0]):\n",
        "        finalList = [Epochs[row],valaccuracy[row],Loss[row]]\n",
        "        writer.writerow(finalList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05rP4SOzbelB",
        "colab_type": "text"
      },
      "source": [
        "# Part4. Predict result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QjFSUcSbjoO",
        "colab_type": "code",
        "outputId": "8a650208-d2da-496c-d60b-1483e69a4b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dataiter = iter(validation_loader)\n",
        "restaurants, labels = dataiter.next()\n",
        "classes = [0, 1]\n",
        "\n",
        "# print restaurants\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "outputs = model(restaurants)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:      1     0     0     1\n",
            "Predicted:      1     1     1     1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrlbZuxGrjZg",
        "colab_type": "text"
      },
      "source": [
        "#Part5. Save and load model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F1U8YAnrmsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwyIzax5rqfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model class must be defined somewhere\n",
        "model = torch.load(PATH)\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiBkxMTmozEO",
        "colab_type": "text"
      },
      "source": [
        "#K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zsxws1-psAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U skorch\n",
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXpoe5whqshB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/DataFest/clean_binary_6340_7000.csv\")\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "X_data = df[df.columns[:-1]].values.astype(np.float32)\n",
        "y_data = df[\"labels\"].astype(\"category\").cat.codes.values.astype(np.int64)\n",
        "print(X_data.shape, y_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbppcdv_qt5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate skorch high-level classifier and perform 5-fold cross validation using cross_val_score()\n",
        "logistic = NeuralNetClassifier(model, max_epochs = 10, lr = 1e-2)\n",
        "scores = cross_val_score(logistic, X_data, y_data, cv = 5, scoring = \"accuracy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQGavgmlqzt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print out results\n",
        "print(scores)\n",
        "print(scores.mean(), scores.std())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe_QUk53VSWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/DataFest/clean_binary_6340_7000.csv\")\n",
        "df = df.sample(frac=1)\n",
        "X_train = df[df.columns[:-1]].values.astype(np.float32)\n",
        "y_train = df[\"labels\"].astype(\"category\").cat.codes.values.astype(np.int64)\n",
        "clf = MLPClassifier((128,128),random_state=1, max_iter=3000).fit(X_train[:11000], y_train[:11000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MduOaJCWPmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df[df.columns[:-1]].values.astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipe_Mjm4WRW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train[:11000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaE7b04eWCij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.score(X_train[11001:], y_train[11001:])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}